<!DOCTYPE html>
<html>
	<head>
		<title>Melike's Logbook</title>
        <style type="text/css">
            h1 {
				color: white;
  				font-family: Times New Roman;
  				font-size: 300%;
  				background: grey;
  				background-size: 1500px 1500px;
  				vertical-align: baseline;
			}
			h2 {
 				color: black;
  				font-family: Times New Roman;
  				font-size: 300%;
  				background: white;
  				background-size: 1500px 1500px;
  				vertical-align: baseline;
			}
            .header {
				margin-left: auto;
			    margin-right: auto;
				text-align: center;
			}
      .report-director {
        font-size: 30px;
      }
        </style>
    </head>
    <body>
        <h1>
			<p class="header">Melike Demirci - T2305 - UThere</p>
		</h1>
	  <p> September <br>
<ul>
  <li> I suggested the selected project idea.</li>
  <li>I conducted research about WebRTC SDKs, and found Agora Web SDK.</li>
</ul>

October <br>
<ul>
  <li> I contributed to Project Spesification Document by writing the introduction, description, and non-functional requirements parts.</li>
  <li>I did research on the factors which can show the attention level of humans, and came up with some analysis suggestions. These were eye blink ratio, gaze, drowsines and talk detection. </li>
  <li>Started to work on Analysis Report with the team.</li>
</ul>

November<br>
<ul>
  <li> I contributed to Analysis Report by writing the introduction, description, and factors in engineering design parts.</li>
  <li>We draw the object and class diagram with Kimya.</li>
  <li>I draw the Sequence Diagrams and wrote their explanations</li>
  <li>I conducted research on how to detect facial landmarks and how to find out if a person is drowsy.</li>
</ul>

December<br>
<ul>
  <li> I tried to implement facial landmark detection with dlib library first but then switched to mediapipe library. Dlib was predicting only 68 points while Mediapipe was predicting 468 points. Also, Mediapipe provides an estimate of the coordinates in 3D space. Therefore, I suggested to the team to work with Mediapipe..</li>
  <li>I worked on blink detection but the initial accuracy was low, it needs to be improved.</li>
  <li>I conducted research about libraries or approaches that could be used for gaze tracking. I found WebGazer.js as one of the best tools and suggested to the team to use it in our project.</li>
  <li>I implemented the drowsiness detection algorithm and tested it on a real-time video.</li>
  <li>I conducted research on emotion recognition practices. I have two suggestions for this issue; training the classification model with transfer learning or using a model directly (Emonet- Official implementation of the paper "Estimation of continuous valence and arousal levels from faces in naturalistic conditions").</li>
  <li>With Kimya, we discussed the ways of getting image data from the javascript and integrating it into the analysis in python.</li>
  <li>Prepared the demo presentation with Kimya.</li>
</ul>

    </body>
</html>
